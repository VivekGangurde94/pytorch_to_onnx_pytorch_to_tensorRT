{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1XUxWVZK4Vj4d7H53RQj5FxmxLkbmBY6h","timestamp":1729154203929}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"P4JEzMg0yvDv","executionInfo":{"status":"ok","timestamp":1729148274790,"user_tz":-330,"elapsed":7357,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}}},"source":["import torch\n","import torchvision\n","from PIL import Image\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"IBIV-fn6zCS2","executionInfo":{"status":"ok","timestamp":1729148279183,"user_tz":-330,"elapsed":1319,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"d124694e-c05b-4457-fe36-76461bff9092","colab":{"base_uri":"https://localhost:8080/"}},"source":["# We will load ResNet 18 in this video\n","resnet = torchvision.models.resnet18(pretrained=True)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 172MB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"c7LWJV2AzJqZ","executionInfo":{"status":"ok","timestamp":1729148285971,"user_tz":-330,"elapsed":1247,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"c293c58a-2eb7-45a8-f81f-d045a3b2bc77","colab":{"base_uri":"https://localhost:8080/"}},"source":["# We will download an example image from PyTorhc\n","import urllib\n","url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\") # Notebook Link will be in description\n","urllib.request.urlretrieve(url, filename)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('dog.jpg', <http.client.HTTPMessage at 0x7b5398f45e40>)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"UERejZI2zu97","executionInfo":{"status":"ok","timestamp":1729148291078,"user_tz":-330,"elapsed":688,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}}},"source":["from torchvision import transforms\n","inp_image = Image.open(filename)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kAdo8NS0GJK","executionInfo":{"status":"ok","timestamp":1729148309515,"user_tz":-330,"elapsed":733,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}}},"source":["preprocess = transforms.Compose([\n","                                 transforms.Resize(256),\n","                                 transforms.CenterCrop(224),\n","                                 transforms.ToTensor(),\n","                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"NtHsiXDWbM2i","executionInfo":{"status":"ok","timestamp":1729148313953,"user_tz":-330,"elapsed":641,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}}},"source":["input_tensor = preprocess(inp_image)\n","inp_batch = input_tensor.unsqueeze(0)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3EiaX2cbTDv","executionInfo":{"status":"ok","timestamp":1729148326173,"user_tz":-330,"elapsed":696,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"b56ec217-72eb-40b7-ca7a-f92edb391ba1","colab":{"base_uri":"https://localhost:8080/"}},"source":["# I am not using a GPU here, if you are, move it to cuda\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","inp_batch.to(device)\n","resnet.to(device)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"y1hk-zwlbdfW","executionInfo":{"status":"ok","timestamp":1729148742150,"user_tz":-330,"elapsed":2143,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"0c5d1d61-3bc3-4a22-8170-6908385cf0ad","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Check if CUDA is available and set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Move the model to the device (if not already done)\n","resnet.to(device)\n","\n","# Move the input tensor to the same device\n","inp_batch = inp_batch.to(device)\n","\n","# Run inference\n","with torch.no_grad():\n","    output = resnet(inp_batch)\n","\n","print(output[0])\n"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-5.7528e-01, -5.2365e-01, -5.9628e-01, -1.5868e+00, -8.1130e-01,\n","        -2.5077e-01, -5.4371e-01,  4.9039e-01,  3.4190e-01, -6.8873e-01,\n","        -1.1116e+00, -1.0390e+00, -4.1218e-01, -1.0470e+00, -1.2576e+00,\n","        -7.3200e-01, -8.5439e-01, -3.2121e-01, -6.5513e-01, -6.1870e-01,\n","        -1.6483e+00, -7.3418e-01, -1.6252e+00,  1.6268e-01, -9.8598e-01,\n","        -1.2476e+00, -9.5957e-01, -1.2001e+00, -9.1442e-01, -3.1844e-01,\n","        -9.0930e-01, -8.9713e-01, -5.4904e-01, -5.5394e-01, -3.5682e-01,\n","        -5.3780e-01,  5.3506e-01, -7.7740e-01, -6.0174e-01, -7.9070e-02,\n","        -7.8334e-01, -1.0649e+00, -1.2019e+00, -5.5904e-01, -8.1106e-01,\n","        -5.4282e-01, -8.6169e-01, -5.3682e-01, -1.3275e+00, -1.2748e+00,\n","        -6.0428e-01,  4.9281e-01, -4.4329e-01, -7.2886e-01, -4.1746e-01,\n","        -1.3161e+00, -5.1891e-01, -1.5703e+00, -7.9879e-01, -7.2835e-01,\n","         6.1612e-01,  6.1869e-02, -2.7226e-01,  6.1549e-02, -8.8719e-01,\n","        -3.8378e-01, -4.2725e-01, -5.2556e-01, -9.6531e-01, -1.0459e+00,\n","        -1.6280e+00,  3.5903e-02, -1.5507e+00, -4.4030e-01, -1.2572e+00,\n","        -1.4319e+00, -2.5422e-03, -7.2224e-01,  1.7417e-01, -8.9847e-02,\n","        -8.6504e-01, -1.6469e+00, -1.6308e-01, -8.0771e-01, -5.5792e-01,\n","        -1.2578e-01,  2.5126e-02,  4.8691e-01, -1.2529e-01, -6.8625e-01,\n","        -1.2531e+00, -1.2859e+00, -2.0917e+00, -3.4436e-01,  1.4976e-01,\n","        -2.1692e+00, -7.7849e-01, -4.5668e-01, -1.3834e+00, -1.2014e-01,\n","        -1.2214e+00, -9.2210e-01, -1.0032e+00, -3.4600e-01,  9.2362e-02,\n","        -4.4541e-01, -2.5902e-01, -1.4543e+00, -1.1668e+00, -1.5370e+00,\n","        -1.1328e+00, -7.5577e-01,  1.1967e+00,  3.3735e-01,  3.3008e-01,\n","        -9.8719e-01, -7.8136e-01, -3.9808e-01,  4.3496e-01, -4.0463e-01,\n","        -8.9357e-01, -7.3510e-02,  3.5069e-01, -1.9185e-03,  9.6302e-01,\n","        -1.1583e-01,  3.0146e-01, -1.4479e+00, -1.2425e+00, -1.2078e+00,\n","        -1.4028e+00, -1.5403e+00, -1.0828e+00, -1.4680e+00, -5.5985e-01,\n","        -1.4722e+00, -9.9437e-01, -1.2704e+00, -1.3052e+00, -1.6226e+00,\n","        -1.6085e+00, -1.7827e+00, -2.1905e+00, -1.6092e+00, -5.6218e-01,\n","        -3.0656e-01, -9.6784e-01, -1.8806e+00, -1.2333e+00, -1.2152e+00,\n","         4.2621e-01,  1.7390e+00, -9.2136e-01, -4.1714e-01,  1.6905e-01,\n","         1.5663e-01, -3.5537e-01, -4.8693e-03,  4.0251e-01,  4.6298e-01,\n","         6.1684e-01,  6.7190e-01,  3.3387e-01,  6.9554e-01,  4.0238e-01,\n","        -8.8738e-02, -4.5617e-02, -2.8053e-01,  7.4453e-01, -8.6298e-02,\n","         3.6839e-02,  1.0247e+00,  6.6924e-01,  4.3446e-01,  4.5414e-01,\n","        -6.4413e-01,  2.5417e-01,  1.3202e-01,  7.9596e-01,  8.3812e-01,\n","         8.5149e-01,  1.7288e-02,  6.7137e-01,  1.2428e-01,  7.0198e-01,\n","         7.9970e-01,  7.2520e-01,  2.5412e-01,  1.8762e-01,  5.7510e-01,\n","        -4.6274e-01,  3.1884e-01,  5.6630e-01,  7.1580e-01, -6.7028e-01,\n","         8.4484e-01,  7.1484e-02,  2.2002e-01,  3.2159e-01,  6.4659e-01,\n","         1.6373e-01,  2.7559e-01,  5.4916e-01,  6.0944e-01,  1.1491e-01,\n","         3.9513e-01,  6.8567e-03,  6.7712e-01,  1.4412e+00,  6.3133e-01,\n","        -5.1119e-02,  4.1350e-01,  4.2206e-01,  1.8112e-02,  8.7043e-02,\n","         4.5425e-01, -4.8110e-02,  2.8389e-01, -3.3570e-01,  6.3144e-01,\n","         1.7860e-01, -1.7167e-01,  2.3472e-01,  8.1866e-01,  5.2062e-01,\n","         6.6111e-01,  2.8813e-01,  1.0215e+00, -2.5164e-01, -1.3781e-01,\n","         2.2557e-01,  7.0388e-01,  5.0763e-01, -2.0018e-02,  8.7012e-01,\n","         1.0785e+00,  6.2869e-01,  5.4602e-01,  8.1995e-01, -1.4324e-01,\n","         6.7476e-01,  1.9249e-02,  5.4890e-01,  5.5672e-01, -1.4388e-01,\n","         4.7775e-01,  6.7230e-01,  2.1518e-01,  8.0737e-01,  3.9162e-01,\n","         5.6342e-01,  7.1813e-01, -7.7738e-01,  8.6567e-01,  1.0242e+00,\n","        -3.6339e-01,  5.1538e-01,  4.3577e-01,  3.2941e-02,  4.6450e-01,\n","         5.2910e-02, -4.1640e-01, -1.7947e-01,  4.7843e-01,  8.3079e-01,\n","         8.1266e-01,  3.3704e-01,  6.4992e-01,  9.6584e-02, -2.5560e-01,\n","        -6.5393e-01, -9.5571e-01, -4.3279e-01,  7.4000e-01, -8.5940e-01,\n","        -9.9858e-01, -8.9817e-01, -7.1743e-01, -1.1263e+00, -4.9285e-01,\n","        -3.0200e-01,  8.4955e-01,  8.6065e-01,  4.6744e-02,  5.1354e-01,\n","         1.0178e+00, -1.0380e-01, -2.0950e-01, -8.6883e-01, -1.6319e+00,\n","        -9.8577e-01, -1.0660e+00, -2.9077e-01, -9.1025e-01, -8.3531e-01,\n","        -8.1824e-01, -7.0589e-01, -1.3193e+00, -3.6561e-01, -3.2661e-02,\n","        -2.0075e+00, -8.5464e-01, -6.4798e-01, -5.3572e-01, -1.1451e+00,\n","        -1.0891e+00, -1.2679e-02, -8.5584e-01, -1.5685e+00, -5.8756e-01,\n","         2.5667e-01, -5.1482e-01, -5.2416e-01,  1.2140e-01,  5.7140e-01,\n","        -6.1437e-01, -9.5442e-01, -1.2876e+00, -1.3290e+00, -8.7181e-01,\n","        -1.7095e+00, -1.2214e+00, -1.4048e+00, -1.7457e+00, -1.5136e+00,\n","        -1.7218e+00, -1.2955e+00,  5.9962e-02, -2.0346e-01, -5.5522e-01,\n","         1.2440e-01, -1.0817e-01,  1.9594e-01,  4.5983e-01, -4.9717e-01,\n","        -6.4395e-01, -1.4109e+00,  1.5615e-01,  8.2910e-01, -1.0047e+00,\n","        -4.0185e-01,  8.4962e-01, -2.8864e-01, -1.2850e+00, -6.6916e-01,\n","         7.2170e-01, -7.0678e-01, -1.5097e+00,  4.4959e-02, -1.3060e+00,\n","        -1.0949e+00, -2.1633e+00, -1.3929e+00, -6.5971e-01, -6.3550e-01,\n","         5.7462e-01,  1.1448e+00,  5.5513e-02,  4.9916e-01,  5.6458e-01,\n","        -2.0871e-01,  4.6459e-01,  1.4446e-01,  1.7278e-01, -3.9860e-01,\n","        -4.6909e-01, -8.8027e-01, -2.5915e-01, -7.2381e-01, -6.0194e-01,\n","        -5.5665e-01, -1.3945e-01, -2.8152e-01,  1.7634e-01, -1.8439e-01,\n","        -8.9010e-01, -1.0084e+00,  2.4797e-01, -3.4731e-01, -4.7694e-01,\n","         3.6102e-01, -2.9289e-01, -1.7649e-01, -5.6183e-01, -6.9513e-01,\n","        -4.4670e-01, -1.0031e+00, -1.1910e+00, -9.3883e-01, -2.6813e-01,\n","         5.9508e-01,  6.5910e-03, -1.5233e+00, -1.7220e+00, -1.5919e-01,\n","         3.3964e-01, -1.2897e+00, -8.0994e-01,  4.5116e-01,  7.7970e-02,\n","        -6.7291e-01,  7.7110e-01,  2.1338e-01, -2.3448e+00, -1.9401e+00,\n","        -7.2104e-01, -1.7680e-01, -4.1212e-01, -3.0852e-01,  9.2721e-01,\n","        -1.9218e-01,  2.7987e-01,  1.9776e+00,  8.1547e-01,  3.9986e-01,\n","         9.1375e-01, -3.1007e-01,  2.9560e-01,  2.6449e-01,  1.0726e+00,\n","         7.7224e-01,  1.2124e+00, -1.2940e-01,  8.5199e-02,  9.5672e-02,\n","        -9.4207e-01, -8.5318e-02,  1.3901e+00,  1.6478e+00,  5.8433e-01,\n","        -7.6470e-01,  3.6533e-02,  3.3630e-01,  6.7302e-01,  6.4358e-01,\n","         1.0540e+00, -2.9855e-01, -4.1564e-01,  3.3220e-01,  4.8436e-01,\n","         7.6603e-01,  4.2200e-01,  5.4981e-03, -5.1857e-01, -5.1249e-01,\n","         1.4610e-01,  3.0012e-01,  1.5608e+00,  8.2378e-01, -7.1608e-01,\n","        -1.7955e-01,  4.4542e-01,  6.5771e-01, -1.5819e-01, -2.2909e-01,\n","         6.3096e-01,  1.5353e+00,  1.2557e+00, -1.1679e-01,  8.4533e-01,\n","        -8.3219e-01,  5.8669e-01,  1.3271e+00,  2.5147e+00,  1.0103e+00,\n","        -1.9642e-01, -1.2026e+00, -8.9783e-02, -8.9753e-02,  1.4716e+00,\n","         1.0510e+00,  4.7062e-01,  7.8824e-02,  9.5958e-01, -9.1588e-03,\n","        -5.9556e-02,  3.6469e-02,  4.6367e-01,  8.1752e-01,  3.9083e-01,\n","        -6.4640e-02,  1.7074e-01,  2.9224e-01, -1.0176e+00, -1.4649e+00,\n","        -1.3160e-01, -2.8007e-01,  1.3515e+00,  1.5342e+00,  1.0279e+00,\n","         5.0047e-01,  8.0168e-01,  6.0182e-01, -1.1907e+00,  1.3030e+00,\n","        -1.0129e+00,  1.1458e-01, -3.8173e-01, -2.9632e-01,  1.3011e+00,\n","        -1.7165e+00,  6.4516e-01,  1.3375e+00,  4.3977e-01,  1.0414e+00,\n","         1.1279e+00,  9.1971e-01,  4.3660e-01,  4.1802e-01,  2.4380e-01,\n","        -1.2280e+00, -8.3175e-01,  7.8895e-01,  4.0208e-01,  1.0671e+00,\n","         1.7985e+00,  4.0870e-01, -1.2702e-01,  1.2249e+00,  7.2940e-01,\n","        -6.4896e-01,  4.4443e-01,  1.0564e+00,  1.7614e+00,  2.7899e-01,\n","        -8.0148e-01, -2.7447e-01, -5.7878e-01,  4.0308e-01,  1.3474e-01,\n","         9.3732e-01,  2.5557e-01, -5.7031e-04, -8.5256e-01,  4.0044e-01,\n","        -6.4891e-01, -5.9635e-01, -5.8094e-01,  7.0717e-02,  1.2418e+00,\n","        -1.2943e+00,  1.6476e+00,  1.1274e+00,  9.5345e-01,  4.7967e-01,\n","         7.2816e-01,  5.5550e-01, -2.0577e+00, -1.2570e+00, -8.4023e-02,\n","        -5.3100e-01,  1.3019e-01,  7.8584e-01, -3.0008e-01, -1.4325e+00,\n","        -8.3026e-01,  1.8017e-01,  2.2834e-01,  1.3556e+00,  9.2945e-01,\n","         2.2389e-01, -1.8692e-01,  7.8044e-01,  4.2425e-02, -1.1474e+00,\n","        -9.6172e-01,  3.1189e-01,  1.0842e+00,  6.6887e-01, -6.9353e-01,\n","         1.1007e+00, -1.7862e-01,  9.0875e-01, -6.7971e-01,  5.3050e-01,\n","        -1.8017e-01, -1.1627e+00,  1.0660e+00,  3.2462e-01,  1.9299e-01,\n","         2.3263e-01, -3.0164e-01,  7.4268e-01,  5.1755e-01,  9.2908e-01,\n","         7.9041e-01, -3.9238e-01,  1.7116e+00,  1.1113e+00,  1.2043e+00,\n","        -4.9119e-01,  6.6940e-01, -7.7156e-01,  1.0273e+00,  2.8023e-01,\n","        -6.1103e-01,  1.1337e+00, -1.7714e-01, -5.0040e-01,  7.1828e-01,\n","         2.1184e+00, -1.8271e-02, -8.6301e-02, -5.2455e-01,  4.9386e-01,\n","         2.6081e-01,  1.2923e+00, -5.0284e-01,  5.6913e-01, -3.8413e-01,\n","         1.0529e+00,  6.3401e-01, -6.8031e-01,  6.1885e-01,  3.9858e-03,\n","         3.8776e-01,  1.0535e+00,  4.7809e-01,  1.9708e+00,  8.4929e-01,\n","         9.8343e-01,  7.2854e-01,  3.2021e-01,  5.4578e-01,  1.1128e-01,\n","        -1.1998e+00,  9.4596e-01, -4.3364e-01, -1.2166e+00,  3.0607e-01,\n","         8.9248e-02,  9.9214e-01,  7.1386e-01,  1.1848e+00, -3.1782e-01,\n","         1.4115e-01,  1.2869e+00,  7.3755e-01,  6.5305e-01,  2.4990e-01,\n","        -1.8139e+00,  1.2908e+00, -5.4783e-03,  1.4609e+00,  7.9004e-01,\n","        -7.7737e-01,  6.5753e-01,  4.7215e-01, -7.6911e-01, -1.4756e+00,\n","         9.9968e-01,  6.3725e-02,  7.2286e-01,  8.4161e-01,  2.3203e-03,\n","         6.8997e-01, -5.3501e-02,  1.7552e-02,  1.9582e-01,  5.6478e-01,\n","        -6.8119e-02, -1.1280e+00, -1.2380e-01, -8.8461e-01,  8.7439e-01,\n","        -8.8359e-02,  1.2693e+00,  5.7315e-01, -9.6169e-01, -3.9960e-01,\n","         1.7958e-01, -5.2199e-01, -3.7258e-01,  6.4822e-01,  1.4828e+00,\n","        -7.6538e-01,  1.7249e+00,  1.0161e+00,  1.0274e+00,  2.0139e-01,\n","         7.0907e-01,  5.8153e-01, -6.9438e-01,  5.7741e-01,  9.9102e-01,\n","        -1.4236e+00, -1.1874e-01, -1.1864e+00, -4.4485e-01, -7.0687e-01,\n","        -6.6959e-01,  7.1121e-01,  9.8894e-01,  6.2130e-01, -9.9132e-01,\n","         8.9357e-01,  1.5438e+00,  3.2651e-02, -5.2027e-01,  8.7978e-01,\n","         2.0033e+00, -2.4803e-01, -2.0164e-01,  4.2318e-01,  6.1807e-01,\n","        -3.7434e-01, -4.3244e-01,  2.1453e-01,  9.3027e-01,  1.9306e-01,\n","         1.0401e+00,  1.0155e+00, -3.4426e-02, -4.8554e-01,  4.6728e-01,\n","        -4.1724e-01,  6.5731e-01, -7.6165e-01, -4.0744e-01,  7.2651e-01,\n","         2.9839e-01,  4.9444e-01,  1.3544e+00,  2.3015e-01, -7.1944e-01,\n","         1.2982e+00, -6.9443e-01, -2.0145e-01,  1.5030e+00, -4.4115e-01,\n","         1.2819e-01,  2.2593e+00, -4.8417e-01,  1.7561e+00, -1.5837e+00,\n","         2.7814e-01, -1.6374e-01,  6.3845e-01,  9.0811e-01,  1.4682e-01,\n","         1.0552e+00, -5.4184e-02,  4.3808e-01,  2.2273e-01,  6.7881e-01,\n","         7.7983e-02,  4.6556e-02,  6.6169e-01,  7.6521e-01,  1.4946e+00,\n","         7.4369e-01, -1.1218e-01,  1.7629e-01,  6.6315e-01,  7.8118e-01,\n","        -6.3662e-01,  1.1003e+00, -1.4469e-01,  1.4798e+00, -1.2823e-01,\n","         9.7587e-02,  8.5046e-01,  4.7894e-01,  8.2835e-01,  1.3322e+00,\n","         9.0194e-01,  4.3356e-01,  4.8013e-01, -3.2948e-03,  1.2268e+00,\n","         3.7039e-01,  2.5165e-01,  1.4572e+00,  7.0646e-01,  7.5315e-01,\n","         2.4781e-01,  4.0210e-01,  6.1107e-01,  1.4129e+00, -8.4484e-01,\n","        -1.0938e+00, -7.9535e-01,  1.0407e+00,  7.9142e-01,  1.5086e+00,\n","         4.7062e-01,  3.5958e-01,  1.3274e+00,  2.6164e-01, -2.9106e-02,\n","         6.7899e-01,  1.0437e+00,  1.6021e+00,  9.2624e-01,  2.9205e-01,\n","         7.6449e-02,  9.4426e-01,  7.2268e-01, -6.7641e-01,  3.4061e-01,\n","        -8.6814e-01,  1.7143e-01, -1.2547e+00, -1.3983e+00,  1.1144e+00,\n","         1.3796e+00,  3.4820e-01,  1.7830e-01,  1.4523e+00,  2.2223e-01,\n","        -5.3141e-01,  1.1894e+00, -3.9217e-01,  1.6709e+00, -1.1455e+00,\n","        -3.1028e-01,  4.4222e-01, -1.0641e+00,  1.6269e+00,  3.8827e-01,\n","        -1.7146e+00, -1.1868e+00,  5.1759e-01,  6.9151e-01,  1.0537e+00,\n","        -9.3016e-01,  2.9718e-01,  8.3115e-01,  1.3507e+00, -6.0320e-01,\n","         1.0096e+00,  4.2477e-01, -6.7314e-01, -1.0745e+00,  1.7136e-01,\n","         4.6268e-01,  1.6579e+00,  1.6505e+00,  1.1181e+00, -8.0565e-01,\n","         1.3359e+00,  6.9234e-01,  4.0772e-01,  6.1659e-01,  5.7465e-01,\n","         1.5141e+00,  6.6376e-01, -5.2982e-01,  4.0971e-01,  9.1501e-01,\n","         1.4412e+00,  1.4742e+00,  1.8803e+00, -5.4843e-01, -3.7123e-01,\n","         8.3588e-01, -6.1746e-01, -2.2628e-01, -3.8170e-01,  1.0524e+00,\n","         1.4035e-01,  1.1660e+00,  9.1842e-01, -1.0597e-01, -4.5427e-01,\n","         6.5066e-01, -2.7410e-02, -4.2347e-01,  1.4988e+00, -3.3841e-01,\n","         8.6075e-01, -1.5405e+00,  1.1234e+00, -1.2051e+00, -2.3031e+00,\n","         4.4220e-01,  1.6047e+00, -2.8791e-01, -3.1250e-01,  1.6160e+00,\n","         9.1546e-01, -2.7770e-01,  1.1090e+00,  1.2180e+00,  7.4661e-03,\n","         3.2078e-01, -4.4795e-01, -2.7414e-01, -1.1583e+00,  2.7263e-01,\n","        -3.6638e-01,  2.2190e-01,  6.7061e-01,  9.8718e-02, -7.0439e-01,\n","        -7.9779e-01,  1.1236e+00,  4.9453e-01,  1.9569e+00,  1.9411e+00,\n","        -1.0268e+00, -4.0576e-01,  1.6948e+00,  8.3195e-01,  9.4947e-01,\n","         1.6879e-01, -4.2001e-01,  1.1760e+00, -1.1179e+00,  8.9171e-01,\n","         1.3314e+00,  1.2372e+00,  8.3630e-01, -5.8158e-01, -1.8984e+00,\n","        -4.4779e-01,  1.3655e-01,  3.0580e-01,  5.2987e-01,  8.2682e-02,\n","        -3.0464e-01,  1.1781e+00, -7.3278e-01,  5.5511e-01, -2.7609e-01,\n","        -9.4565e-01, -9.8375e-01, -5.7818e-01, -7.4729e-02,  1.5727e+00,\n","        -1.1533e-01,  1.0581e-01,  5.1986e-01, -1.5767e+00,  1.6775e-01,\n","        -4.5408e-01,  3.2380e-01,  4.3946e-01,  8.8743e-02,  4.0892e-02,\n","        -2.8573e-01, -6.9080e-01, -2.4578e-01,  2.8712e-01, -5.0191e-01,\n","        -7.4428e-01, -1.3573e+00,  4.3557e-01,  7.3568e-01, -3.5624e-01,\n","        -6.5085e-03, -5.0947e-01, -5.1886e-01,  3.0049e-02,  8.2583e-01,\n","        -4.8366e-01, -2.4606e-01, -5.2112e-01, -6.6142e-03, -9.3616e-01,\n","         2.3176e-01,  4.0361e-01, -3.8768e-01, -7.5640e-01, -1.2520e+00,\n","        -1.3794e-01,  4.3322e-01, -5.3742e-01,  9.1163e-01,  2.9425e-02,\n","        -2.1326e-01,  1.0122e+00, -4.4790e-01, -5.2434e-01, -2.1152e+00,\n","         9.1463e-01, -1.6263e+00,  3.2764e-01,  3.7764e-02, -8.0407e-01,\n","        -7.1054e-01,  2.1376e-01,  6.1424e-01, -6.0288e-01, -9.9783e-01,\n","        -1.3878e+00, -2.4099e+00,  1.4867e+00, -2.7772e-01, -9.4172e-01,\n","        -3.0212e-01, -1.2991e+00, -9.5575e-01, -1.9579e+00, -8.0077e-01,\n","        -3.9739e-01,  1.1103e-01, -4.7772e-01,  1.3124e+00,  1.1137e+00],\n","       device='cuda:0')\n"]}]},{"cell_type":"code","source":["!pip install onnx\n"],"metadata":{"id":"6BcZowLRTbHY","executionInfo":{"status":"ok","timestamp":1729148869477,"user_tz":-330,"elapsed":7391,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"8fbb9f02-cbea-40f0-9083-aefca8c002af","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx\n","  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx\n","Successfully installed onnx-1.17.0\n"]}]},{"cell_type":"code","metadata":{"id":"2V0NHmowbjH2","executionInfo":{"status":"ok","timestamp":1729148875892,"user_tz":-330,"elapsed":2343,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}}},"source":["# Output of shape 1000, confidence scores for each of the imagenet classes\n","# Now we will save this model.\n","import torch.onnx\n","torch.onnx.export(resnet,\n","                  inp_batch,\n","                  \"resnet18.onnx\",\n","                  export_params=True,\n","                  opset_version=10)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJHka5fkcKeS"},"source":["# Now our model is saved to onnx format.\n","# I will cover loading onnx models in a later tutorial"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install onnx onnxruntime\n"],"metadata":{"id":"wTxZhjeuUKMC","executionInfo":{"status":"ok","timestamp":1729149064000,"user_tz":-330,"elapsed":5225,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"2caf704f-7156-4306-a4d2-8bc2161340c3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.3)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.19.2\n"]}]},{"cell_type":"code","source":["import onnx\n","import onnxruntime as ort\n","import numpy as np\n","\n","# Load the ONNX model\n","onnx_model = onnx.load(\"resnet18.onnx\")\n","\n","# Check the model\n","onnx.checker.check_model(onnx_model)\n","\n","# Create an ONNX Runtime session\n","ort_session = ort.InferenceSession(\"resnet18.onnx\")\n","\n","# Prepare the input tensor (make sure it matches the input shape expected by the model)\n","# Example: Assuming input shape is (1, 3, 224, 224) for a single image\n","# You may need to preprocess your image data accordingly.\n","inp_batch = np.random.rand(1, 3, 224, 224).astype(np.float32)  # Replace with your actual input\n","\n","# Run inference\n","ort_inputs = {ort_session.get_inputs()[0].name: inp_batch}\n","ort_outs = ort_session.run(None, ort_inputs)\n","\n","# Print the output\n","print(ort_outs[0])  # Output will have shape (1, 1000) for ImageNet classes\n"],"metadata":{"id":"RsZufYUEULtz","executionInfo":{"status":"ok","timestamp":1729149092783,"user_tz":-330,"elapsed":1038,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"4522b6ea-3b03-4c9a-a95d-40f8c97d45d1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-1.74610233e+00  7.52400279e-01  1.44568992e+00  1.20903885e+00\n","   1.00830436e+00 -3.72980177e-01  9.35472846e-01 -2.54331440e-01\n","  -1.69022393e+00 -3.49500120e-01  9.76200104e-01  2.09227777e+00\n","   1.27292275e+00  2.64228868e+00  2.52153134e+00  1.04383612e+00\n","   1.37361670e+00  1.27904058e-01  1.15513086e+00  1.56909895e+00\n","   5.06293058e-01  1.85575235e+00  1.63468373e+00  1.46408570e+00\n","   2.09236413e-01  5.63738048e-01  1.05344415e+00  1.18055689e+00\n","   3.33715796e-01 -1.03683901e+00 -4.15844560e-01  1.36346972e+00\n","  -4.00536209e-01  1.04197407e+00  2.36583853e+00 -4.95091438e-01\n","  -4.94675279e-01 -1.51020885e-01  1.66281486e+00  3.23169619e-01\n","   2.55100393e+00  1.24703646e+00  2.07989788e+00  4.45683539e-01\n","   1.82828331e+00  4.75498408e-01  2.23872757e+00 -3.40613127e-01\n","   4.19860482e-02  2.60864735e-01  1.44900918e+00 -1.46857440e+00\n","   1.97769988e+00  1.72681808e+00  7.83777893e-01  9.69367027e-01\n","   6.57507777e-01  4.67452943e-01  1.71592116e+00  2.08936405e+00\n","   1.55284512e+00  6.80460393e-01  1.96430147e-01 -2.69221485e-01\n","   6.67286992e-01  2.64069080e+00  1.32356256e-01 -6.94906652e-01\n","   3.88319492e-01  2.54117727e+00  2.01793337e+00  3.13366175e+00\n","   5.81333637e-01  2.64181137e+00  7.89685726e-01  2.87077141e+00\n","   1.17260170e+00  2.21254349e+00  4.39694738e+00  3.69221067e+00\n","  -2.31834590e-01  1.36114264e+00  4.14426714e-01 -1.61940145e+00\n","  -7.25065112e-01  1.71967924e+00 -1.15609534e-01  2.05709934e+00\n","   5.18733799e-01  1.94206905e+00 -9.78600383e-02  5.55999339e-01\n","   3.34037399e+00  6.43064499e-01  2.73818970e+00 -4.85788107e-01\n","   1.18532908e+00 -1.22201788e+00 -1.06792033e-01  1.09389305e-01\n","   3.78510296e-01 -2.02773929e+00 -1.27826703e+00  1.10394406e+00\n","  -3.92032862e-02 -1.36058795e+00 -1.46380329e+00  2.15769863e+00\n","  -1.58101475e+00 -6.55972660e-02 -8.48905921e-01  6.32786560e+00\n","   1.86694098e+00  1.40924811e+00  2.06323838e+00 -1.72886789e+00\n","  -1.35735226e+00  7.11256623e-01 -2.77970463e-01 -4.89860415e-01\n","   9.39261019e-01 -1.75087428e+00 -4.18239146e-01 -9.59115088e-01\n","   1.29852676e+00  1.42480218e+00  2.31307745e+00  1.30198479e+00\n","   1.59413505e+00  1.74568367e+00 -1.11569047e-01  8.71580482e-01\n","   1.58766890e+00  1.08709216e+00  1.27487266e+00  1.31276846e-02\n","  -3.67833972e-01  6.67533994e-01  9.73297060e-01  1.33377409e+00\n","   1.19477332e+00  2.37508893e+00  8.57050002e-01  1.96738362e+00\n","   8.59914720e-01 -3.60529065e-01  7.66664147e-01  3.91938567e-01\n","  -9.17263567e-01 -1.34718075e-01 -3.90356600e-01 -5.51497400e-01\n","  -2.53039908e+00 -1.56432688e-01 -1.02198589e+00 -8.63377035e-01\n","  -1.20049238e+00 -1.41555619e+00 -8.70992064e-01 -7.15372324e-01\n","  -1.92027056e+00  3.82618606e-02  1.06770992e-01 -4.55352843e-01\n","  -2.32204646e-01 -1.65586197e+00 -3.32425773e-01 -2.40133381e+00\n","  -4.59767401e-01 -1.07273638e+00 -1.44095051e+00  2.00521260e-01\n","  -5.19032419e-01 -7.09043980e-01 -1.20570397e+00 -2.46422958e+00\n","  -1.45111501e+00 -2.17583609e+00 -1.42664135e-01 -1.58452773e+00\n","  -9.44195926e-01 -1.70669246e+00 -9.79219317e-01 -1.27353740e+00\n","  -1.35080028e+00 -1.15269816e+00 -1.78919673e+00  1.15859121e-01\n","  -2.53842735e+00 -9.71488714e-01 -1.39017606e+00 -1.23317039e+00\n","  -1.21216655e+00 -2.54825568e+00 -2.36590958e+00  2.15377808e-01\n","  -3.81865084e-01 -2.36286592e+00 -2.16606331e+00 -1.21873784e+00\n","  -2.44549465e+00 -1.55354154e+00 -1.01895511e+00  8.33487809e-02\n","  -3.23168159e-01 -1.68117487e+00 -1.54381609e+00 -6.18152022e-01\n","  -1.37318158e+00  3.88359457e-01 -1.41765308e+00 -1.55210435e+00\n","  -9.46364582e-01 -1.06213534e+00 -1.73460162e+00 -5.45003533e-01\n","  -2.04252958e+00 -3.81419659e-01 -8.00785184e-01 -1.72501481e+00\n","  -2.82230139e+00 -1.48387313e+00 -1.86478233e+00 -3.88457179e-01\n","  -1.75135517e+00 -1.08622837e+00 -1.97444892e+00 -1.81629729e+00\n","  -2.68614554e+00 -1.54782462e+00 -6.07680798e-01 -1.79487026e+00\n","  -8.40659440e-01 -3.42516661e+00 -1.48657703e+00 -1.56010246e+00\n","  -1.03965569e+00 -8.65139186e-01 -3.74563992e-01 -7.84292996e-01\n","  -1.58531785e+00 -1.15252817e+00 -1.05118823e+00 -1.66519690e+00\n","  -3.60313344e+00 -1.46288589e-01 -1.69111204e+00 -1.31957173e+00\n","  -8.91517639e-01 -6.98369741e-01 -1.14764583e+00 -8.54995847e-01\n","  -2.85461664e+00 -8.58212829e-01 -1.04541874e+00 -3.46072197e+00\n","  -2.11088085e+00 -1.43318760e+00 -5.00350595e-01 -6.34346128e-01\n","  -2.45004487e+00 -1.81690621e+00 -3.28168440e+00  1.09842688e-01\n","  -6.92896664e-01 -5.68708301e-01 -1.03389311e+00 -2.70357084e+00\n","  -2.51278710e+00 -1.73655474e+00 -1.34282613e+00 -2.21073723e+00\n","  -2.63055414e-02  9.79992747e-02 -2.03921747e+00 -7.36140907e-01\n","  -9.51896369e-01 -7.33044267e-01 -8.72938514e-01 -2.83135444e-01\n","  -5.90361714e-01 -2.01821059e-01 -2.65523225e-01 -3.82885754e-01\n","  -3.92364860e-01 -2.39539266e-01 -1.92322373e+00 -2.19264841e+00\n","  -2.08599019e+00 -2.33358479e+00 -2.95639205e+00 -1.87360454e+00\n","  -2.07509589e+00 -1.06974804e+00 -2.04559088e+00 -1.25526524e+00\n","  -1.08899570e+00 -2.42089510e+00 -2.70749688e-01 -3.24232042e-01\n","   3.46691608e-02  2.83970332e+00  1.36451113e+00  2.35780907e+00\n","   1.14211583e+00  9.53119218e-01  1.35254681e+00  2.20436144e+00\n","   2.24560452e+00 -1.67699546e-01  3.11893773e+00  2.24552059e+00\n","   2.48062420e+00  3.59631443e+00  3.09450245e+00  2.94160724e+00\n","   2.98533773e+00  3.07920003e+00  4.46469069e+00  3.17104721e+00\n","   2.83806229e+00 -3.29174250e-01 -1.47834826e+00 -1.34838343e-01\n","   6.17308021e-01  1.29923642e-01  1.11545265e+00  2.17670512e+00\n","   1.63896561e-01 -3.77679527e-01 -7.19491899e-01  7.62724876e-03\n","  -8.18181992e-01 -6.86728597e-01 -1.39954412e+00 -7.30417550e-01\n","  -1.42365217e+00 -8.99684548e-01 -1.66695273e+00 -2.29370546e+00\n","  -2.09894133e+00 -3.80918169e+00 -2.37890601e+00 -1.34963727e+00\n","  -1.14627910e+00 -2.06373429e+00 -7.59010792e-01 -1.31136823e+00\n","  -2.26004457e+00 -7.72741556e-01 -1.95420623e-01 -5.13420820e-01\n","  -1.01927817e+00 -3.19149196e-01 -7.25787640e-01 -3.47360206e+00\n","   3.03749949e-01 -8.08300376e-01 -1.50509298e-01  1.51136190e-01\n","  -1.05932021e+00  4.78445530e-01 -5.64812899e-01  3.21765959e-01\n","  -8.24716151e-01 -1.54662156e+00 -2.40495396e+00 -5.20153761e-01\n","  -2.11253405e+00 -1.91829777e+00 -9.44504738e-01 -1.98129702e+00\n","  -1.80688536e+00 -1.05458307e+00 -1.63195372e-01 -1.47509885e+00\n","  -3.26897413e-01 -1.56520188e-01 -1.39103413e+00 -1.95068502e+00\n","  -1.92745972e+00 -1.20999217e+00 -7.89436996e-01 -3.26707721e-01\n","  -1.59910178e+00 -2.11294627e+00 -1.65906143e+00 -2.31072569e+00\n","  -2.43541121e+00 -1.13984549e+00 -2.76672751e-01  3.73015881e-01\n","  -1.50074077e+00 -1.57289457e+00 -4.86963868e-01  1.26822829e+00\n","   3.17654103e-01  2.54008591e-01 -4.67245102e-01  1.49212480e-02\n","  -2.28820252e+00 -1.01564908e+00  1.92717981e+00  1.20312679e+00\n","   1.48976064e+00  2.33785319e+00 -1.35052097e+00 -1.43770874e+00\n","  -1.96481085e+00  1.62042594e+00 -8.78215253e-01 -4.78972018e-01\n","   2.93877721e-01  7.14075744e-01 -6.62908971e-01 -2.33424759e+00\n","  -2.88226306e-01  1.50664163e+00  4.62968874e+00  1.86574697e+00\n","   9.92366552e-01  6.90994263e-02  2.19362676e-02 -2.03626060e+00\n","  -2.21340489e+00 -6.91875517e-01  9.35329854e-01 -5.37306130e-01\n","  -1.27629328e+00  1.67699933e+00 -8.71201634e-01 -1.66389108e+00\n","   1.56929481e+00 -2.01416969e-01 -7.20296025e-01 -1.98489690e+00\n","  -7.10043371e-01  8.86014998e-01  2.08232343e-01 -1.54861224e+00\n","   1.93192315e+00  1.19485688e+00 -2.90141284e-01  1.59176052e+00\n","  -2.97558546e-01 -4.30537075e-01  2.48498130e+00 -4.29942131e-01\n","   7.50718713e-01 -6.61302507e-01 -8.89563382e-01  2.71449661e+00\n","  -4.16957617e-01 -6.25255227e-01 -1.81623614e+00  3.23025513e+00\n","   5.03361225e-01  2.22061634e-01  1.28637516e+00  2.77952939e-01\n","   1.55670238e+00 -7.26166070e-01  1.52786136e+00  4.39070404e-01\n","   1.55818975e+00 -5.40717483e-01 -1.18306494e+00 -2.59918785e+00\n","  -6.27803087e-01 -1.25103629e+00  1.43244290e+00  2.31721759e-01\n","   2.18402743e-02  1.85361433e+00  6.37850344e-01 -1.30314457e+00\n","  -4.03911114e+00 -5.58820486e-01  1.12102091e+00 -2.64864892e-01\n","   2.61318862e-01  1.98759031e+00 -1.57192111e-01 -6.68899417e-01\n","   3.64089817e-01  1.26916444e+00 -2.08689749e-01  1.69820070e+00\n","   2.53988314e+00 -5.11708319e-01 -2.93775827e-01  2.96082735e-01\n","   3.56001318e-01 -1.49876761e+00  3.65432650e-01 -1.37425840e+00\n","   3.63474429e-01 -1.34506202e+00 -1.52782023e-01  1.55886698e+00\n","  -2.53706396e-01 -8.39530647e-01  2.85169631e-01  6.42356396e-01\n","   1.13163257e+00  6.86401367e-01  3.47411186e-01  1.40263617e+00\n","   7.21015707e-02 -2.88635588e+00  5.68707943e-01 -1.31256342e+00\n","   2.74169803e+00  4.14490700e-04  2.74438500e-01  3.13378304e-01\n","  -1.98533463e+00  1.66821432e+00 -9.99296010e-01 -7.41243482e-01\n","  -1.35220325e+00 -1.11798465e+00  5.10826148e-03  1.60278583e+00\n","  -1.54696548e+00 -8.00208688e-01 -2.93208569e-01 -1.02060091e+00\n","   1.16672635e-01 -1.46129221e-01  1.88702941e+00  1.15848279e+00\n","  -8.59223485e-01  1.14162850e+00 -5.86835742e-02 -1.39488351e+00\n","  -6.93329096e-01 -6.00411832e-01  1.23448074e+00 -5.23244500e-01\n","   8.48451495e-01  1.65419281e-01  1.93679976e+00 -2.88516521e-01\n","  -3.27548981e-01  1.31678784e+00 -2.65041366e-03 -2.70523930e+00\n","  -3.62771600e-01  3.45981646e+00 -1.83446670e+00  2.29286551e-01\n","   1.97233945e-01  9.19889212e-01  2.84887552e-01 -1.46255016e+00\n","  -1.63841709e-01  1.47864330e+00  1.17574656e+00  1.00421762e+00\n","  -9.17248368e-01 -4.20394957e-01 -1.43819615e-01  3.61826277e+00\n","  -2.38625264e+00 -1.35829735e+00 -6.83271706e-01  1.14435506e+00\n","  -1.59528065e+00 -1.73728859e+00 -2.30640590e-01 -2.06987429e+00\n","   1.34108138e+00 -2.99459398e-02  2.36925125e+00 -1.97493911e+00\n","  -1.47869349e+00 -4.67112124e-01 -9.51429605e-01 -9.31769609e-01\n","  -2.40308762e+00 -1.31590080e+00 -2.31372499e+00  1.95622474e-01\n","   2.10713482e+00 -7.19654560e-03 -7.08422124e-01  2.51007247e+00\n","  -1.79337189e-01  2.48807847e-01 -9.59889412e-01  1.53015828e+00\n","   1.67925608e+00  1.41317880e+00 -1.46508008e-01 -1.78632164e+00\n","   1.31550932e+00  1.53672957e+00  9.51315165e-02 -2.30251148e-01\n","   3.11120582e+00 -3.44771743e-02 -2.43330419e-01 -2.09184790e+00\n","   2.07459259e+00  2.82329035e+00  1.79570818e+00 -1.39570311e-01\n","   1.21548557e+00 -1.25934362e+00  1.23208523e+00  2.15731144e+00\n","  -2.05865765e+00  1.84955919e+00 -1.17761660e+00  1.60725325e-01\n","   3.82833362e+00 -8.34212661e-01  2.89809704e+00  2.36343575e+00\n","   2.53159022e+00 -1.44440818e+00  3.23047423e+00  3.74692726e+00\n","  -3.99948806e-01 -4.24026847e-01  2.50546598e+00 -1.08833528e+00\n","   1.02536941e+00  2.35019302e+00 -2.65884221e-01  8.62460494e-01\n","   1.11457956e+00  1.80866361e+00 -3.25546598e+00  1.19860971e+00\n","  -3.61695170e-01 -5.46287447e-02 -3.46448123e-01 -6.31401062e-01\n","   8.82256985e-01  3.51285577e-01 -1.53629827e+00  3.36029381e-01\n","   4.94159412e+00 -9.28713679e-01 -2.14884609e-01  7.17082560e-01\n","  -9.56754923e-01 -3.75705898e-01  2.05216050e+00 -1.46216750e+00\n","  -6.96347952e-01 -2.09760129e-01 -1.62962091e+00  3.52233618e-01\n","  -1.54260576e+00  2.90762448e+00 -1.36932790e-01  8.91390264e-01\n","  -6.96271837e-01 -2.47656512e+00  2.29843760e+00 -1.69304585e+00\n","   1.22975934e+00  4.50921059e-03  7.53119826e-01 -1.24642909e-01\n","   2.18638003e-01 -6.22000337e-01 -1.47917652e+00 -1.21139002e+00\n","   1.58396363e-01  2.21720219e+00  2.47329140e+00 -1.79831624e+00\n","  -1.61873507e+00  3.67883754e+00 -9.61301804e-01  3.83963251e+00\n","   8.08977485e-01  2.53448415e+00  2.31653643e+00  1.48137414e+00\n","   1.59949720e+00  1.99535608e-01 -1.38518319e-01 -2.67701578e+00\n","   6.39288306e-01 -1.81810844e+00 -2.43639016e+00 -3.77494842e-01\n","   1.13706315e+00  4.31750059e-01 -9.32209730e-01  1.55045509e+00\n","   1.93375885e+00 -3.39355230e-01 -1.37082291e+00  5.25611281e-01\n","   1.73070264e+00  2.96871948e+00 -9.81476903e-01 -1.43120098e+00\n","   7.15448797e-01 -2.06257606e+00 -9.54875886e-01 -1.59315437e-01\n","  -2.90673316e-01  1.52054596e+00  2.26616716e+00  1.65900218e+00\n","   1.68699837e+00 -7.10760653e-01  3.40640783e+00 -1.37107003e+00\n","   4.54309583e-01 -2.52580166e+00  9.79934871e-01  1.10362101e+00\n","   2.89986348e+00  6.89624548e-01  3.27381730e+00  8.02941680e-01\n","   7.61386156e-02  1.52365804e+00  3.19400907e-01  6.53734744e-01\n","   6.90505207e-02 -7.40157008e-01 -9.66754615e-01  1.35132074e+00\n","  -4.92485762e-02  2.09805298e+00 -2.53580117e+00  6.17897689e-01\n","   1.79739130e+00  1.91559529e+00  6.01935506e-01 -3.28256178e+00\n","   9.59505558e-01 -5.71596622e-02 -8.41186583e-01 -8.79596293e-01\n","   2.01553011e+00  4.52796817e-01  2.02041698e+00 -5.64357638e-01\n","   5.39111674e-01  2.81205654e+00 -7.37717032e-01 -8.71205091e-01\n","   2.63629580e+00  1.18680716e+00  1.33388788e-01  8.27071667e-01\n","  -1.24357831e+00 -2.06903744e+00  1.34287477e-02  1.05334258e+00\n","   3.33423615e-02  1.87255001e+00 -2.40036392e+00  3.30257845e+00\n","   6.51743054e-01  3.05612355e-01 -3.19220161e+00  3.77750564e+00\n","  -4.48677599e-01  3.31468153e+00  1.22900021e+00  8.01770806e-01\n","   2.62833524e+00  2.28178167e+00  1.33307743e+00 -5.02701640e-01\n","   9.18668747e-01  1.87611222e+00 -4.25692350e-02 -1.71035242e+00\n","   4.50625241e-01 -4.55998719e-01  1.34776735e+00  4.22998428e+00\n","   4.07381296e+00 -1.74458206e+00 -2.02959120e-01 -3.58002722e-01\n","  -2.21079111e+00 -3.21861774e-01 -1.27343655e+00  8.90652776e-01\n","   2.56677419e-01 -5.78136891e-02 -6.00355148e-01  1.07964277e+00\n","   7.54535273e-02 -1.45790958e+00  1.80960548e+00  1.02792978e-02\n","  -2.60424471e+00  4.19787288e-01 -8.54063690e-01 -3.13223392e-01\n","   1.65679419e+00  6.29094124e-01  6.50912642e-01 -1.87931478e+00\n","  -1.42458379e-01  1.34630442e+00 -1.04780197e+00  6.84338868e-01\n","   2.76501918e+00  1.83412290e+00  5.53389430e-01  1.07227802e+00\n","   1.55154836e+00 -2.18845987e+00  2.36536264e+00 -9.16641653e-01\n","  -2.74058676e+00 -2.94045568e-01 -1.27766454e+00  2.85228372e-01\n","  -4.41715956e-01 -1.87472248e+00  1.81807303e+00 -1.49289203e+00\n","   2.01642442e+00 -2.16270781e+00 -5.80708623e-01 -9.19580340e-01\n","  -8.56664181e-01  1.09989071e+00  6.78575486e-02 -5.30359074e-02\n","   6.56750053e-02  8.94444108e-01  2.05992043e-01  4.68792737e-01\n","   1.22895169e+00 -1.50772542e-01  8.69526342e-02 -1.01598763e+00\n","   3.97047186e+00  4.85333872e+00  2.14098740e+00 -1.10135078e+00\n","   6.03602886e-01  7.78733134e-01 -2.06823826e-01  9.90488589e-01\n","   2.77021551e+00 -8.74106765e-01 -1.56419992e+00  3.14061356e+00\n","  -4.02940130e+00 -1.72861052e+00  9.46747065e-02 -1.52911305e-01\n","  -2.40751529e+00  1.91993296e-01  1.23157036e+00 -6.29409552e-02\n","  -1.59049332e+00 -4.22122955e+00 -1.34205759e+00 -1.18281889e+00\n","   1.24833965e+00 -1.72492206e-01  1.56247437e-01 -1.09641254e-01\n","   2.14175916e+00  4.87217814e-01 -2.78789473e+00 -3.93242836e-01\n","  -1.16429245e+00 -1.85628676e+00 -1.55889535e+00  1.13128901e+00\n","   9.67017531e-01 -1.06815577e+00  8.89920831e-01  1.68100643e+00\n","  -2.30609596e-01  3.33333522e-01 -1.79354489e+00 -1.98561382e+00\n","  -4.53813225e-01  4.08581346e-02 -2.17649400e-01 -5.10843277e-01\n","   4.69713068e+00  2.67066097e+00 -9.28571463e-01  1.58045554e+00\n","  -4.03734088e-01 -1.42304409e+00  1.46096659e+00  7.91860640e-01\n","   8.09002876e-01  7.45148480e-01  2.91945505e+00 -1.23937331e-01\n","   1.21001029e+00 -2.70865619e-01 -8.17519963e-01  1.28609002e+00\n","   2.23612237e+00  2.77278692e-01  1.71359921e+00  2.12614655e-01\n","  -2.12900257e+00  1.14854038e+00 -8.30488801e-01 -1.22031903e+00\n","  -1.24496841e+00 -9.69323516e-01 -4.71352607e-01  9.16852832e-01\n","   1.71274662e+00  1.17785239e+00  6.32130921e-01 -5.77342451e-01\n","  -1.12300098e+00 -1.68661654e-01 -2.84830952e+00  3.07399660e-01\n","   3.04101169e-01  1.56744409e+00 -8.45120966e-01 -2.57222772e-01\n","   8.39559734e-02 -1.54081082e+00 -1.67258906e+00 -1.11724544e+00\n","  -2.01731539e+00  2.19630331e-01 -7.86554575e-01 -5.15375078e-01\n","  -5.68742931e-01 -1.72781944e+00 -1.11416149e+00 -1.02111959e+00\n","  -1.58631730e+00  1.21947974e-02 -1.78420138e+00 -1.28404927e+00\n","   1.25233221e+00  8.44128788e-01  1.47371256e+00  1.27941346e+00\n","   7.20759153e-01 -1.42562389e-01  1.17357433e+00 -1.29158258e+00\n","  -1.61584640e+00  2.15405151e-01 -3.05120707e-01 -3.86243165e-02\n","   8.75492543e-02  8.34386647e-01 -1.31369710e+00  4.09035206e-01\n","  -3.86303008e-01 -1.71104074e+00  1.63285148e+00  1.92656517e+00\n","   1.86592531e+00 -8.88592303e-02 -1.10746384e+00  1.91026187e+00\n","   5.50734997e-02 -9.63062525e-01  1.74036436e-02  1.25865936e+00\n","   1.17986000e+00  2.41433549e+00  1.45109403e+00 -1.33860159e+00\n","   1.95544052e+00  8.95136654e-01 -1.66122508e+00  2.19441473e-01\n","  -1.37623310e-01  5.18065989e-02 -6.36887908e-01  5.34689069e-01\n","   1.45405424e+00  4.09319162e-01  3.74260604e-01 -1.39603555e+00\n","  -1.55363774e+00 -2.56401157e+00 -1.83245492e+00 -1.38903952e+00\n","  -2.32069492e+00 -6.92678690e-01  2.14470148e-01  2.32823539e+00]]\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","import torchvision.transforms as transforms\n","\n","# Load and preprocess an image\n","image = Image.open(\"/content/dog.jpg\")\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),  # Converts to (C, H, W) format\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization\n","])\n","\n","# Apply the transformations\n","inp_batch = transform(image).unsqueeze(0).numpy()  # Add batch dimension\n"],"metadata":{"id":"wkcRF60BUTwj","executionInfo":{"status":"ok","timestamp":1729149194070,"user_tz":-330,"elapsed":1661,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","# Assuming inp_batch is already prepared as a NumPy array, convert it to a PyTorch tensor\n","inp_batch_tensor = torch.from_numpy(inp_batch)\n","\n","# Move the tensor to the same device as the model (e.g., GPU if using)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","inp_batch_tensor = inp_batch_tensor.to(device)\n","\n","# Ensure the model is also on the same device\n","resnet.to(device)\n","\n","# Run inference with the PyTorch model\n","with torch.no_grad():\n","    pytorch_output = resnet(inp_batch_tensor)\n","\n","# Convert output to NumPy array for comparison\n","pytorch_output_np = pytorch_output.cpu().numpy()  # Move back to CPU and convert to NumPy\n","\n"],"metadata":{"id":"ib5Oa52RUsUm","executionInfo":{"status":"ok","timestamp":1729149460690,"user_tz":-330,"elapsed":631,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["import onnx\n","import onnxruntime as ort\n","import numpy as np\n","\n","# Load the ONNX model\n","onnx_model = onnx.load(\"resnet18.onnx\")\n","onnx.checker.check_model(onnx_model)\n","ort_session = ort.InferenceSession(\"resnet18.onnx\")\n","\n","# Ensure the input for ONNX is also prepared correctly (already as NumPy array)\n","ort_inputs = {ort_session.get_inputs()[0].name: inp_batch}  # Ensure this is a NumPy array\n","onnx_output = ort_session.run(None, ort_inputs)[0]  # Get the output\n"],"metadata":{"id":"eMkZGibXVM1J","executionInfo":{"status":"ok","timestamp":1729149479751,"user_tz":-330,"elapsed":664,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Compare the outputs\n","difference = np.abs(pytorch_output_np - onnx_output)\n","max_difference = np.max(difference)\n","mean_difference = np.mean(difference)\n","\n","print(f'Max difference: {max_difference}')\n","print(f'Mean difference: {mean_difference}')\n","\n","# Optionally, check if the outputs are close within a tolerance\n","tolerance = 1e-5\n","if np.all(difference < tolerance):\n","    print(\"The outputs from the PyTorch model and ONNX model are close enough!\")\n","else:\n","    print(\"The outputs differ beyond the tolerance level.\")\n"],"metadata":{"id":"qjH_nmv4VyU1","executionInfo":{"status":"ok","timestamp":1729149498432,"user_tz":-330,"elapsed":665,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"b8df4dc1-fd36-471b-a86c-caf2817bee68","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Max difference: 6.67572021484375e-06\n","Mean difference: 1.3396246458796668e-06\n","The outputs from the PyTorch model and ONNX model are close enough!\n"]}]},{"cell_type":"code","source":["import time\n","\n","# Measure inference time for the PyTorch model\n","start_time_pytorch = time.time()\n","\n","with torch.no_grad():\n","    pytorch_output = resnet(inp_batch_tensor)\n","\n","end_time_pytorch = time.time()\n","pytorch_inference_time = end_time_pytorch - start_time_pytorch\n","\n","print(f'PyTorch inference time: {pytorch_inference_time:.6f} seconds')\n"],"metadata":{"id":"u9EBO-YtV23j","executionInfo":{"status":"ok","timestamp":1729149653112,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"04f71249-88d3-4e75-f301-8f1ec1e3bbd1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch inference time: 0.006326 seconds\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import onnx\n","import onnxruntime as ort\n","import time\n","\n","# Load the ONNX model\n","onnx_model = onnx.load(\"resnet18.onnx\")\n","onnx.checker.check_model(onnx_model)\n","ort_session = ort.InferenceSession(\"resnet18.onnx\")\n","\n","# Prepare the input tensor for PyTorch (as a PyTorch tensor)\n","inp_batch_tensor = torch.from_numpy(inp_batch).to(device)  # Ensure it is on the right device\n","\n","# Measure inference time for the PyTorch model\n","start_time_pytorch = time.time()\n","with torch.no_grad():\n","    pytorch_output = resnet(inp_batch_tensor)\n","end_time_pytorch = time.time()\n","pytorch_inference_time = end_time_pytorch - start_time_pytorch\n","\n","# Convert output to NumPy for comparison\n","pytorch_output_np = pytorch_output.cpu().numpy()\n","\n","# Prepare input for ONNX model (as a NumPy array)\n","ort_inputs = {ort_session.get_inputs()[0].name: inp_batch}\n","\n","# Measure inference time for the ONNX model\n","start_time_onnx = time.time()\n","onnx_output = ort_session.run(None, ort_inputs)[0]\n","end_time_onnx = time.time()\n","onnx_inference_time = end_time_onnx - start_time_onnx\n","\n","# Print the inference times\n","print(f'PyTorch inference time: {pytorch_inference_time:.6f} seconds')\n","print(f'ONNX inference time: {onnx_inference_time:.6f} seconds')\n"],"metadata":{"id":"gi1bD1QJXAl8","executionInfo":{"status":"ok","timestamp":1729149807535,"user_tz":-330,"elapsed":674,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"317d733c-c478-4552-aebd-5a07d133b6b9","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch inference time: 0.003366 seconds\n","ONNX inference time: 0.035591 seconds\n"]}]},{"cell_type":"code","source":["import time\n","\n","# Define the number of runs for averaging\n","num_runs = 100\n","\n","# Function to measure average inference time for PyTorch\n","def measure_inference_time(model, input_tensor, num_runs=100):\n","    total_time = 0.0\n","    for _ in range(num_runs):\n","        start_time = time.time()\n","        with torch.no_grad():\n","            _ = model(input_tensor)\n","        total_time += time.time() - start_time\n","    return total_time / num_runs\n","\n","# Measure average times for PyTorch\n","pytorch_average_time = measure_inference_time(resnet, inp_batch_tensor, num_runs)\n","print(f'Average PyTorch inference time over {num_runs} runs: {pytorch_average_time:.6f} seconds')\n","\n","\n"],"metadata":{"id":"JCPvs1y7XCWu","executionInfo":{"status":"ok","timestamp":1729149979775,"user_tz":-330,"elapsed":618,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"3bf2a9b1-7088-4a73-8339-80324efc4a14","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Average PyTorch inference time over 100 runs: 0.002912 seconds\n"]}]},{"cell_type":"code","source":["# Function to measure average inference time for ONNX\n","def measure_onnx_inference_time(session, inputs, num_runs=100):\n","    total_time = 0.0\n","    for _ in range(num_runs):\n","        start_time = time.time()\n","        _ = session.run(None, inputs)\n","        total_time += time.time() - start_time\n","    return total_time / num_runs\n","\n","# Measure average times for ONNX\n","onnx_average_time = measure_onnx_inference_time(ort_session, ort_inputs, num_runs)\n","print(f'Average ONNX inference time over {num_runs} runs: {onnx_average_time:.6f} seconds')"],"metadata":{"id":"AgckYdBJXbKA","executionInfo":{"status":"ok","timestamp":1729149994221,"user_tz":-330,"elapsed":5103,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"87a6664b-7e23-49e6-a7de-244a5f472b17","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Average ONNX inference time over 100 runs: 0.043631 seconds\n"]}]},{"cell_type":"code","source":["!pip install torch-tensorrt -U\n"],"metadata":{"id":"c1IFHkiXXu2G","executionInfo":{"status":"ok","timestamp":1729152674828,"user_tz":-330,"elapsed":150429,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"45bd29e8-9cbd-4bc3-b50a-bbb69b289d91","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-tensorrt\n","  Downloading torch_tensorrt-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_34_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: torch<2.5.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (2.4.1+cu121)\n","Collecting tensorrt==10.1.0 (from torch-tensorrt)\n","  Downloading tensorrt-10.1.0.tar.gz (16 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorrt-cu12-bindings==10.1.0 (from torch-tensorrt)\n","  Downloading tensorrt_cu12_bindings-10.1.0-cp310-none-manylinux_2_17_x86_64.whl.metadata (627 bytes)\n","Collecting tensorrt-cu12-libs==10.1.0 (from torch-tensorrt)\n","  Downloading tensorrt_cu12_libs-10.1.0.tar.gz (630 bytes)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (24.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (1.26.4)\n","Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (4.12.2)\n","Collecting tensorrt-cu12 (from tensorrt==10.1.0->torch-tensorrt)\n","  Downloading tensorrt-cu12-10.5.0.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.10/dist-packages (from tensorrt-cu12-libs==10.1.0->torch-tensorrt) (12.6.77)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.5.0,>=2.4.0->torch-tensorrt) (3.16.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.5.0,>=2.4.0->torch-tensorrt) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.5.0,>=2.4.0->torch-tensorrt) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.5.0,>=2.4.0->torch-tensorrt) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.5.0,>=2.4.0->torch-tensorrt) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.5.0,>=2.4.0->torch-tensorrt) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.5.0,>=2.4.0->torch-tensorrt) (1.3.0)\n","Downloading torch_tensorrt-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_34_x86_64.whl (3.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorrt_cu12_bindings-10.1.0-cp310-none-manylinux_2_17_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt-cu12-libs, tensorrt-cu12\n","  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorrt: filename=tensorrt-10.1.0-py2.py3-none-any.whl size=16333 sha256=e38001f49b627799008da4d4a82be18807ffa16434b8ddd4c8ecca12733dae17\n","  Stored in directory: /root/.cache/pip/wheels/f5/55/f5/a1836546c0d92da062e9365a0323953f5e6a0a5f51d46da503\n","  Building wheel for tensorrt-cu12-libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorrt-cu12-libs: filename=tensorrt_cu12_libs-10.1.0-py2.py3-none-manylinux_2_17_x86_64.whl size=1056270840 sha256=1ad13c26b3f441267a746df6859e44eb0e8da78d4382458d1fd2eb7675abd49f\n","  Stored in directory: /root/.cache/pip/wheels/18/d0/78/3c2ad1c46e9434a528a07e9d9b8402a96c9a4d55fa2aca0773\n","  Building wheel for tensorrt-cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorrt-cu12: filename=tensorrt_cu12-10.5.0-py2.py3-none-any.whl size=17556 sha256=ab72a551bf1225ff012b4920c6b198931aea3ecf0ccb43dce450542884b37883\n","  Stored in directory: /root/.cache/pip/wheels/31/83/8a/84edbd0d600c1b334a5ac98e18626a458dc8a70d83d9c5ccbe\n","Successfully built tensorrt tensorrt-cu12-libs tensorrt-cu12\n","Installing collected packages: tensorrt-cu12-bindings, tensorrt-cu12-libs, tensorrt-cu12, tensorrt, torch-tensorrt\n","Successfully installed tensorrt-10.1.0 tensorrt-cu12-10.5.0 tensorrt-cu12-bindings-10.1.0 tensorrt-cu12-libs-10.1.0 torch-tensorrt-2.4.0\n"]}]},{"cell_type":"code","source":["import torch\n","\n","# Make sure the model is in evaluation mode\n","resnet.eval()\n","\n","# Move the model to GPU (if available)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","resnet = resnet.to(device)\n"],"metadata":{"id":"ofi0wx2hhZii","executionInfo":{"status":"ok","timestamp":1729152794128,"user_tz":-330,"elapsed":687,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["import torch_tensorrt\n","\n","# Prepare your input example (on the right device)\n","input_data = inp_batch_tensor  # Ensure this is a PyTorch tensor on the right device\n","\n","# Convert the PyTorch model to TensorRT using Torch-TensorRT\n","trt_model = torch_tensorrt.compile(resnet, inputs=[torch_tensorrt.Input(input_data.shape)], enabled_precisions={torch.float})\n","\n","print(\"Model has been successfully converted to TensorRT!\")\n"],"metadata":{"id":"q-sLJHc3ibf0","executionInfo":{"status":"ok","timestamp":1729152827978,"user_tz":-330,"elapsed":13680,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"592d1b28-a4ad-4d8e-bcb2-630b73521c4b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:torch_tensorrt.dynamo.conversion.aten_ops_converters:Unable to import quantization op. Please install modelopt library (https://github.com/NVIDIA/TensorRT-Model-Optimizer?tab=readme-ov-file#installation) to add support for compiling quantized models\n","WARNING:root:Given dtype that does not have direct mapping to torch (dtype.unknown), defaulting to torch.float\n","WARNING:root:Given dtype that does not have direct mapping to torch (dtype.unknown), defaulting to torch.float\n"]},{"output_type":"stream","name":"stdout","text":["Model has been successfully converted to TensorRT!\n"]}]},{"cell_type":"code","source":["# Run inference with the TensorRT model\n","with torch.no_grad():\n","    trt_output = trt_model(input_data)\n","\n","# Convert the output to CPU (if necessary) and compare with the original model\n","trt_output_np = trt_output.cpu().numpy()\n"],"metadata":{"id":"xbTptilYiglk","executionInfo":{"status":"ok","timestamp":1729152884101,"user_tz":-330,"elapsed":635,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Compare TensorRT and PyTorch outputs\n","difference = np.abs(pytorch_output_np - trt_output_np)\n","max_difference = np.max(difference)\n","mean_difference = np.mean(difference)\n","\n","print(f'Max difference between TensorRT and PyTorch outputs: {max_difference}')\n","print(f'Mean difference between TensorRT and PyTorch outputs: {mean_difference}')\n"],"metadata":{"id":"SYmfjJ-3ixdo","executionInfo":{"status":"ok","timestamp":1729152929185,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"b5d80389-b6a3-4c0b-85ae-17d5cf6bf209","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Max difference between TensorRT and PyTorch outputs: 5.7220458984375e-06\n","Mean difference between TensorRT and PyTorch outputs: 1.3225153452367522e-06\n"]}]},{"cell_type":"code","source":["trt_model = torch_tensorrt.compile(resnet, inputs=[torch_tensorrt.Input(input_data.shape)], enabled_precisions={torch.half})\n"],"metadata":{"id":"mb9TMKM_i8Ye","executionInfo":{"status":"ok","timestamp":1729152986334,"user_tz":-330,"elapsed":21860,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"3670007e-ee21-4ca5-8e5d-7d7f8b40bc7b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Given dtype that does not have direct mapping to torch (dtype.unknown), defaulting to torch.float\n","WARNING:root:Given dtype that does not have direct mapping to torch (dtype.unknown), defaulting to torch.float\n"]}]},{"cell_type":"code","source":["import time\n","import torch\n","\n","# Make sure the model is in evaluation mode and on the right device\n","resnet.eval()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","resnet = resnet.to(device)\n","\n","# Prepare input tensor (ensure it's on the right device)\n","inp_batch_tensor = inp_batch_tensor.to(device)\n","\n","# Measure inference time for the PyTorch model\n","start_time_pytorch = time.time()\n","\n","with torch.no_grad():\n","    pytorch_output = resnet(inp_batch_tensor)\n","\n","end_time_pytorch = time.time()\n","pytorch_inference_time = end_time_pytorch - start_time_pytorch\n","\n","print(f'PyTorch inference time: {pytorch_inference_time:.6f} seconds')\n"],"metadata":{"id":"Uz5-3yBsjFPw","executionInfo":{"status":"ok","timestamp":1729153024019,"user_tz":-330,"elapsed":725,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"5913101e-d1a1-4dae-88a8-8da19b3691cf","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch inference time: 0.004895 seconds\n"]}]},{"cell_type":"code","source":["import torch_tensorrt\n","\n","# Convert the model to TensorRT (if you haven't done this already)\n","trt_model = torch_tensorrt.compile(resnet, inputs=[torch_tensorrt.Input(inp_batch_tensor.shape)], enabled_precisions={torch.float})\n","\n","# Measure inference time for the TensorRT model\n","start_time_trt = time.time()\n","\n","with torch.no_grad():\n","    trt_output = trt_model(inp_batch_tensor)\n","\n","end_time_trt = time.time()\n","trt_inference_time = end_time_trt - start_time_trt\n","\n","print(f'TensorRT inference time: {trt_inference_time:.6f} seconds')\n"],"metadata":{"id":"iGjt2vJ2jTnZ","executionInfo":{"status":"ok","timestamp":1729153045110,"user_tz":-330,"elapsed":6248,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"df2f112e-138f-4a0b-8692-03921197db1a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Given dtype that does not have direct mapping to torch (dtype.unknown), defaulting to torch.float\n","WARNING:root:Given dtype that does not have direct mapping to torch (dtype.unknown), defaulting to torch.float\n"]},{"output_type":"stream","name":"stdout","text":["TensorRT inference time: 0.000971 seconds\n"]}]},{"cell_type":"code","source":["import time\n","import torch\n","import torch_tensorrt\n","\n","# Ensure models are in evaluation mode and moved to the appropriate device (CUDA)\n","resnet.eval()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","resnet = resnet.to(device)\n","inp_batch_tensor = inp_batch_tensor.to(device)\n","\n","# Measure PyTorch inference time\n","start_time_pytorch = time.time()\n","with torch.no_grad():\n","    pytorch_output = resnet(inp_batch_tensor)\n","end_time_pytorch = time.time()\n","pytorch_inference_time = end_time_pytorch - start_time_pytorch\n","print(f'PyTorch inference time: {pytorch_inference_time:.6f} seconds')\n","\n","# Convert PyTorch model to TensorRT model\n","trt_model = torch_tensorrt.compile(resnet, inputs=[torch_tensorrt.Input(inp_batch_tensor.shape)], enabled_precisions={torch.float})\n","\n","# Measure TensorRT inference time\n","start_time_trt = time.time()\n","with torch.no_grad():\n","    trt_output = trt_model(inp_batch_tensor)\n","end_time_trt = time.time()\n","trt_inference_time = end_time_trt - start_time_trt\n","print(f'TensorRT inference time: {trt_inference_time:.6f} seconds')\n","\n","# Compare outputs\n","pytorch_output_np = pytorch_output.cpu().numpy()\n","trt_output_np = trt_output.cpu().numpy()\n","\n","max_difference = np.max(np.abs(pytorch_output_np - trt_output_np))\n","mean_difference = np.mean(np.abs(pytorch_output_np - trt_output_np))\n","print(f'Max difference between TensorRT and PyTorch outputs: {max_difference}')\n","print(f'Mean difference between TensorRT and PyTorch outputs: {mean_difference}')\n"],"metadata":{"id":"pfJtbLIWjXao","executionInfo":{"status":"ok","timestamp":1729153173938,"user_tz":-330,"elapsed":6767,"user":{"displayName":"Vivek Gangurde","userId":"09342273900865889886"}},"outputId":"c06e6532-65da-4df6-d3f4-697b5c8a27df","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Given dtype that does not have direct mapping to torch (dtype.unknown), defaulting to torch.float\n"]},{"output_type":"stream","name":"stdout","text":["PyTorch inference time: 0.011577 seconds\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:root:Given dtype that does not have direct mapping to torch (dtype.unknown), defaulting to torch.float\n"]},{"output_type":"stream","name":"stdout","text":["TensorRT inference time: 0.001370 seconds\n","Max difference between TensorRT and PyTorch outputs: 5.7220458984375e-06\n","Mean difference between TensorRT and PyTorch outputs: 1.3225153452367522e-06\n"]}]},{"cell_type":"markdown","source":["#Inference Times:\n","* PyTorch Inference Time: 0.011577 seconds\n","* ONNX Inference Time: 0.035591 seconds\n","* TensorRT Inference Time: 0.001370 seconds\n","#Max and Mean Differences in Outputs (compared to PyTorch):\n","ONNX Model:\n","* Max difference: 6.67572021484375e-06\n","* Mean difference: 1.3396246458796668e-06\n","* TensorRT Model:\n","* Max difference: 5.7220458984375e-06\n","* Mean difference: 1.3225153452367522e-06\n","#Performance:\n","TensorRT is the fastest, with an inference time of 0.001370 seconds, roughly 8.4 times faster than PyTorch and about 26 times faster than ONNX.\n","PyTorch is faster than ONNX, but still slower than TensorRT.\n","Accuracy:\n","The differences in output between the models are minimal, indicating that both ONNX and TensorRT models provide results very close to the original PyTorch model. The accuracy is well-preserved during conversion."],"metadata":{"id":"9BC_31nRkUjv"}},{"cell_type":"code","source":[],"metadata":{"id":"3j8BiWphldNT"},"execution_count":null,"outputs":[]}]}
